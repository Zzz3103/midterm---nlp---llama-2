# LLAMA 2 - Nh√≥m 5
Nh√≥m ch√∫ng t√¥i ƒë√£ tri·ªÉn khai m·ªôt m√¥ h√¨nh d·ª±a tr√™n LLaMA 2 v·ªõi c√°c th√†nh ph·∫ßn ch√≠nh sau:

Rotary Positional Embeddings (RoPE): T√≠nh to√°n embedding theo g√≥c quay b·∫±ng c√°ch d√πng s·ªë ph·ª©c v√† ph√©p bi·∫øn ƒë·ªïi sin/cos.

RMS-Norm: Chu·∫©n h√≥a ƒë·∫ßu v√†o b·∫±ng chu·∫©n trung b√¨nh b√¨nh ph∆∞∆°ng ƒë·ªÉ c·∫£i thi·ªán ·ªïn ƒë·ªãnh hu·∫•n luy·ªán.

LlamaLayer: G·ªìm normalization, attention, residual connection v√† m·∫°ng feedforward.

AdamW Optimizer: √Åp d·ª•ng t·ªëi ∆∞u h√≥a Adam k·∫øt h·ª£p weight decay t√°ch bi·ªát r√µ r√†ng.

C∆° ch·∫ø Attention: Tri·ªÉn khai attention chu·∫©n v·ªõi Q, K, V v√† normalization theo chi·ªÅu key.

H√†m Generate: Sinh vƒÉn b·∫£n v·ªõi temperature sampling v√† x·ª≠ l√Ω ng·∫Øt chu·ªói ƒë·ªông.

üî¨ C√°c thi·∫øt l·∫≠p v√† k·∫øt qu·∫£ th·ª≠ nghi·ªám:
Setting 1: Text continuation.

Setting 2: Zero-shot prompting v·ªõi SST-5 v√† CFIMDB.

Setting 3: Fine-tuning ph√¢n lo·∫°i t√°c v·ª• v·ªõi SST-5 v√† CFIMDB.

ƒê√£ th·ª≠ nghi·ªám v·ªõi nhi·ªÅu si√™u tham s·ªë nh∆∞ dropout, n_layers, v√† n_kv_heads.
